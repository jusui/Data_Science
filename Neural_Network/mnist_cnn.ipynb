{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST for Experts\n",
    "\n",
    "### CNNを使って精度改善を狙う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# one_hot:1つだけ1で，それ以外は0\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# C++ backendへの接続とコード構成を柔軟化する\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力画像と目的出力クラスのためのノードを作成することで計算グラフの組み立てを開始\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables(784 inputs, 10 classes)\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多層畳み込みネットワークの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重みの初期化\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 畳み込み\n",
    "def conv2d(x, W):\n",
    "    # strides: 1 pixel ずらして畳み込み, padding:0なので出力==入力('SAME')\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プーリング:サイズを小さくして特徴量を抽出\n",
    "# MAX pooling:2×2ブロック内の最大値を採用して数値のゆらぎを削減, strides:2pixelずらす\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一畳み込み層(5 * 5のマスに1つの1つの値，それが32個)\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_14:0\", shape=(?, 28, 28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# -1:式の結果に合わせて動的にパラメータを決定\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "print(x_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered valueをReLuで値を変換, 特徴のない値を切り捨てて計算量を削減\n",
    "# 1層目にフィルター\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 次元圧縮\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二層\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2) # 次元削減"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 読み出し層\n",
    "W_fc2 = weight_variable([1024, 10]) # 1024行 × 0 ~ 9\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1\n",
      "step 100, training accuracy 0.78\n",
      "step 200, training accuracy 0.84\n",
      "step 300, training accuracy 0.94\n",
      "step 400, training accuracy 0.92\n",
      "step 500, training accuracy 1\n",
      "step 600, training accuracy 0.92\n",
      "step 700, training accuracy 0.94\n",
      "step 800, training accuracy 0.96\n",
      "step 900, training accuracy 0.96\n",
      "step 1000, training accuracy 0.98\n",
      "step 1100, training accuracy 0.94\n",
      "step 1200, training accuracy 0.98\n",
      "step 1300, training accuracy 0.94\n",
      "step 1400, training accuracy 0.94\n",
      "step 1500, training accuracy 0.96\n",
      "step 1600, training accuracy 0.96\n",
      "step 1700, training accuracy 1\n",
      "step 1800, training accuracy 0.98\n",
      "step 1900, training accuracy 0.98\n",
      "test accuracy 0.9768\n"
     ]
    }
   ],
   "source": [
    "# 各\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_conv, labels = y_)) # https://github.com/ibab/tensorflow-wavenet/issues/223\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy) # grad descent\n",
    "\n",
    "# 正解数: y_conv最大値を返す\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "\n",
    "# 精度\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# モデルの訓練\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(2000): # 20000\n",
    "    # 次のランダムな50個を取り出す\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i % 100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict = {x:batch[0], y_:batch[1],\n",
    "                                                    keep_prob:1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x:batch[0], y_:batch[1], keep_prob:0.5})\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: mnist.test.images,\n",
    "                                                 y_:mnist.test.labels,\n",
    "                                                 keep_prob: 1.0}))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorFlow_1_3_0]",
   "language": "python",
   "name": "Python [tensorFlow_1_3_0]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
